{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6657e5a1",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fc3d862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\admin\\anaconda3\\lib\\site-packages (3.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: h5py in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras) (3.10.0)\n",
      "Requirement already satisfied: namex in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras) (0.0.7)\n",
      "Requirement already satisfied: rich in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras) (0.10.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from optree->keras) (4.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from rich->keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9d79253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (61.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.7)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (21.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: namex in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.10.0)\n",
      "Requirement already satisfied: rich in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.16.1->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d72b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48e7ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\n",
    "from keras.models import Model,Sequential\n",
    "from keras.optimizers import Adam,SGD,RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "609985e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d095e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import model_from_json\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1906685",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Intialize image data generator with rescaling\n",
    "train_data_gen = ImageDataGenerator(rescale = 1./255)\n",
    "validation_data_gen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9fdf68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = 'E:/Minor Project/Datasets/images dataset/train' #loading dataset\n",
    "test_directory = 'E:/Minor Project/Datasets/images dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98b2bca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "#preprocess train data\n",
    "train_generator = train_data_gen.flow_from_directory( #generates batches\n",
    "          'E:/Minor Project/Datasets/images dataset/train',\n",
    "          target_size =(48,48), #resize\n",
    "          batch_size =64, \n",
    "          color_mode=\"grayscale\",\n",
    "          class_mode='categorical', \n",
    "          shuffle=True  # Ensure data is shuffled for better randomness\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3320e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "#preprocess test data\n",
    "validation_generator = validation_data_gen.flow_from_directory(\n",
    "          'E:/Minor Project/Datasets/images dataset/test',\n",
    "          target_size =(48,48),\n",
    "          batch_size =64,\n",
    "          color_mode=\"grayscale\",\n",
    "          class_mode='categorical',\n",
    "          shuffle=False  # Validation data should not be shuffled\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e03df12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "emotion_model = Sequential()\n",
    "\n",
    "emotion_model.add(Conv2D(32, kernel_size=(3,3), activation='relu',input_shape=(48,48,1)))\n",
    "# adds 2d convolutional layer, 32 filters or kernel, extract features\n",
    "emotion_model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size =(2,2)))\n",
    "#spatial dimensions of feature map , reducing dimensions \n",
    "emotion_model.add(Dropout(0.25))\n",
    "#learns training data and also the noise \n",
    "emotion_model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size =(2,2)))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size =(2,2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(1024, activation='relu'))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "emotion_model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=Adam(learning_rate=0.0001,decay =1e-6),\n",
    "                      metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea84c873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m922s\u001b[0m 2s/step - accuracy: 0.2504 - loss: 1.8312 - val_accuracy: 0.3292 - val_loss: 1.7180\n",
      "Epoch 2/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 968ms/step - accuracy: 0.3423 - loss: 1.6732 - val_accuracy: 0.4047 - val_loss: 1.5508\n",
      "Epoch 3/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 294ms/step - accuracy: 0.3979 - loss: 1.5522 - val_accuracy: 0.4379 - val_loss: 1.4719\n",
      "Epoch 4/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 242ms/step - accuracy: 0.4282 - loss: 1.4892 - val_accuracy: 0.4646 - val_loss: 1.4092\n",
      "Epoch 5/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 243ms/step - accuracy: 0.4545 - loss: 1.4278 - val_accuracy: 0.4657 - val_loss: 1.3838\n",
      "Epoch 6/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 269ms/step - accuracy: 0.4834 - loss: 1.3641 - val_accuracy: 0.4999 - val_loss: 1.3135\n",
      "Epoch 7/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 368ms/step - accuracy: 0.4985 - loss: 1.3194 - val_accuracy: 0.5085 - val_loss: 1.2905\n",
      "Epoch 8/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 448ms/step - accuracy: 0.5109 - loss: 1.2864 - val_accuracy: 0.5196 - val_loss: 1.2600\n",
      "Epoch 9/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 864ms/step - accuracy: 0.5264 - loss: 1.2464 - val_accuracy: 0.5300 - val_loss: 1.2329\n",
      "Epoch 10/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 755ms/step - accuracy: 0.5411 - loss: 1.2109 - val_accuracy: 0.5371 - val_loss: 1.2090\n",
      "Epoch 11/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 806ms/step - accuracy: 0.5604 - loss: 1.1867 - val_accuracy: 0.5478 - val_loss: 1.1841\n",
      "Epoch 12/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 953ms/step - accuracy: 0.5652 - loss: 1.1536 - val_accuracy: 0.5609 - val_loss: 1.1642\n",
      "Epoch 13/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 838ms/step - accuracy: 0.5727 - loss: 1.1319 - val_accuracy: 0.5567 - val_loss: 1.1649\n",
      "Epoch 14/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 791ms/step - accuracy: 0.5863 - loss: 1.1044 - val_accuracy: 0.5620 - val_loss: 1.1479\n",
      "Epoch 15/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 877ms/step - accuracy: 0.6007 - loss: 1.0670 - val_accuracy: 0.5706 - val_loss: 1.1363\n",
      "Epoch 16/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 542ms/step - accuracy: 0.6118 - loss: 1.0437 - val_accuracy: 0.5645 - val_loss: 1.1386\n",
      "Epoch 17/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 572ms/step - accuracy: 0.6180 - loss: 1.0309 - val_accuracy: 0.5800 - val_loss: 1.1136\n",
      "Epoch 18/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 263ms/step - accuracy: 0.6285 - loss: 1.0043 - val_accuracy: 0.5814 - val_loss: 1.1193\n",
      "Epoch 19/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 255ms/step - accuracy: 0.6387 - loss: 0.9805 - val_accuracy: 0.5896 - val_loss: 1.0966\n",
      "Epoch 20/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 237ms/step - accuracy: 0.6431 - loss: 0.9607 - val_accuracy: 0.5887 - val_loss: 1.0934\n",
      "Epoch 21/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 237ms/step - accuracy: 0.6542 - loss: 0.9260 - val_accuracy: 0.5890 - val_loss: 1.0931\n",
      "Epoch 22/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 217ms/step - accuracy: 0.6652 - loss: 0.9053 - val_accuracy: 0.6009 - val_loss: 1.0842\n",
      "Epoch 23/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 215ms/step - accuracy: 0.6803 - loss: 0.8725 - val_accuracy: 0.5978 - val_loss: 1.0787\n",
      "Epoch 24/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 223ms/step - accuracy: 0.6856 - loss: 0.8603 - val_accuracy: 0.6020 - val_loss: 1.0809\n",
      "Epoch 25/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 218ms/step - accuracy: 0.6920 - loss: 0.8401 - val_accuracy: 0.6032 - val_loss: 1.0759\n",
      "Epoch 26/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 221ms/step - accuracy: 0.7074 - loss: 0.8083 - val_accuracy: 0.6018 - val_loss: 1.0776\n",
      "Epoch 27/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 548ms/step - accuracy: 0.7125 - loss: 0.7862 - val_accuracy: 0.6046 - val_loss: 1.0690\n",
      "Epoch 28/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 581ms/step - accuracy: 0.7258 - loss: 0.7549 - val_accuracy: 0.6098 - val_loss: 1.0874\n",
      "Epoch 29/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 451ms/step - accuracy: 0.7331 - loss: 0.7341 - val_accuracy: 0.6095 - val_loss: 1.0928\n",
      "Epoch 30/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 230ms/step - accuracy: 0.7384 - loss: 0.7127 - val_accuracy: 0.6121 - val_loss: 1.0795\n",
      "Epoch 31/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 334ms/step - accuracy: 0.7473 - loss: 0.6916 - val_accuracy: 0.6133 - val_loss: 1.0800\n",
      "Epoch 32/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 271ms/step - accuracy: 0.7510 - loss: 0.6826 - val_accuracy: 0.6144 - val_loss: 1.0957\n",
      "Epoch 33/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 261ms/step - accuracy: 0.7661 - loss: 0.6456 - val_accuracy: 0.6067 - val_loss: 1.1063\n",
      "Epoch 34/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 230ms/step - accuracy: 0.7680 - loss: 0.6366 - val_accuracy: 0.6135 - val_loss: 1.0995\n",
      "Epoch 35/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 233ms/step - accuracy: 0.7823 - loss: 0.6023 - val_accuracy: 0.6156 - val_loss: 1.1042\n",
      "Epoch 36/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 233ms/step - accuracy: 0.7874 - loss: 0.5950 - val_accuracy: 0.6167 - val_loss: 1.1059\n",
      "Epoch 37/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 224ms/step - accuracy: 0.7903 - loss: 0.5740 - val_accuracy: 0.6165 - val_loss: 1.1284\n",
      "Epoch 38/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 227ms/step - accuracy: 0.8025 - loss: 0.5475 - val_accuracy: 0.6172 - val_loss: 1.1064\n",
      "Epoch 39/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 680ms/step - accuracy: 0.8040 - loss: 0.5317 - val_accuracy: 0.6162 - val_loss: 1.1457\n",
      "Epoch 40/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 2s/step - accuracy: 0.8154 - loss: 0.5137 - val_accuracy: 0.6172 - val_loss: 1.1264\n",
      "Epoch 41/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m677s\u001b[0m 1s/step - accuracy: 0.8215 - loss: 0.4947 - val_accuracy: 0.6170 - val_loss: 1.1522\n",
      "Epoch 42/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1681s\u001b[0m 4s/step - accuracy: 0.8273 - loss: 0.4847 - val_accuracy: 0.6208 - val_loss: 1.1655\n",
      "Epoch 43/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m707s\u001b[0m 2s/step - accuracy: 0.8316 - loss: 0.4717 - val_accuracy: 0.6165 - val_loss: 1.1824\n",
      "Epoch 44/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 1000ms/step - accuracy: 0.8367 - loss: 0.4539 - val_accuracy: 0.6166 - val_loss: 1.1713\n",
      "Epoch 45/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 1s/step - accuracy: 0.8352 - loss: 0.4490 - val_accuracy: 0.6205 - val_loss: 1.1913\n",
      "Epoch 46/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 695ms/step - accuracy: 0.8429 - loss: 0.4304 - val_accuracy: 0.6181 - val_loss: 1.1891\n",
      "Epoch 47/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 420ms/step - accuracy: 0.8473 - loss: 0.4191 - val_accuracy: 0.6268 - val_loss: 1.1802\n",
      "Epoch 48/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 751ms/step - accuracy: 0.8576 - loss: 0.3998 - val_accuracy: 0.6225 - val_loss: 1.2066\n",
      "Epoch 49/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 523ms/step - accuracy: 0.8645 - loss: 0.3728 - val_accuracy: 0.6241 - val_loss: 1.2320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50:\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 536ms/step - accuracy: 0.8708 - loss: 0.3694 - val_accuracy: 0.6268 - val_loss: 1.2130\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = len(train_generator)\n",
    "validation_steps = len(validation_generator)\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}:\")\n",
    "    train_history = emotion_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=1,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_steps,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74844929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model architecture to JSON\n",
    "model_json = emotion_model.to_json()\n",
    "with open(\"emotion_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98918b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label = ['angry','disgust','fear','happy','neutral','sad','surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "380ef764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "def ef(image_path):\n",
    "    # Load the image\n",
    "    img = load_img(image_path, target_size=(48, 48), color_mode='grayscale')\n",
    "    # Convert the image to an array\n",
    "    img_array = img_to_array(img)\n",
    "    # Expand dimensions to match the input shape of the model\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    # Normalize the pixel values\n",
    "    img_array /= 255.0\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c351eb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image is of neutral\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Model prediction is: Neutral\n"
     ]
    }
   ],
   "source": [
    "# Assuming you've defined and trained your model earlier and named it emotion_model\n",
    "image_path = r'E:\\Minor Project\\Datasets\\images dataset\\train\\neutral\\Training_98123.jpg'\n",
    "print(\"Original image is of neutral\")\n",
    "img = ef(image_path)\n",
    "pred = emotion_model.predict(img)  # Using emotion_model as your model variable\n",
    "pred_label = np.argmax(pred)\n",
    "\n",
    "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "predicted_emotion_label = emotion_labels[pred_label]\n",
    "print(\"Model prediction is:\", predicted_emotion_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecc1c1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb9979e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image is of neutral\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "model prediction is  surprise\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f9264f1040>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_path = r'E:\\Minor Project\\Datasets\\images dataset\\train\\neutral\\Training_98123.jpg'\n",
    "print(\"Original image is of Dneutral\")\n",
    "img = ef(image_path)\n",
    "pred = emotion_model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \",pred_label)\n",
    "plt.imshow(img.reshape(48,48),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725206fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
